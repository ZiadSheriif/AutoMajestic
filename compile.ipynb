{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import graphviz\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "# dumping the nfa to a file json\n",
    "def dump_json(nfa, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(nfa, f, ensure_ascii=False, indent=6)\n",
    "\n",
    "\n",
    "def get_keys_by_group_state(group):\n",
    "    keys = []\n",
    "    for state in group:\n",
    "        for key, value in state.items():\n",
    "            keys.append(key)\n",
    "\n",
    "    return keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class RegexValidator:\n",
    "    def __init__(self, regex):\n",
    "        self.regex = regex\n",
    "        self.postfix = None\n",
    "\n",
    "    def validate(self):\n",
    "        try:\n",
    "            if self.regex.count('[') != self.regex.count(']'):\n",
    "                print(\"Invalid regular expression: unmatched brackets\")\n",
    "                return False\n",
    "            re.compile(self.regex)\n",
    "        except re.error:\n",
    "            print(\"Invalid regex:\" , self.regex)\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def post_validate(self):\n",
    "        # we will order regular expressions syntax is listed as in the documentation\n",
    "        # supported regex syntax\n",
    "        operators = {\"(\":0,\"|\": 1, \".\": 2, \"?\": 3, \"+\": 4, \"*\": 5}\n",
    "        regex = self.regex\n",
    "\n",
    "        # Check if the regular expression contains any character classes (denoted by square brackets).\n",
    "        # If a character class is found, the function converts it to an \"alternation\" #!`() between the characters inside the class`.\n",
    "        # as example: [xyz] => (x|y|z) and [0-9] will be converted to (0|1|2|3|4|5|6|7|8|9) and so on.\n",
    "\n",
    "        for i in range(len(regex)):\n",
    "            operator = regex[i]\n",
    "            if operator == \"[\":\n",
    "                j = i + 1\n",
    "                while regex[j] != \"]\":\n",
    "                    if regex[j].isalnum() and regex[j + 1].isalnum():\n",
    "                        regex = regex[: j + 1] + \"|\" + regex[j + 1 :]\n",
    "                        # print(\"regex[j + 1:]: \", regex[j + 1:])\n",
    "                        # print(\"regex[: j + 1]: \", regex[: j + 1])\n",
    "                    j += 1\n",
    "\n",
    "        # then, replace the character class with the new alternation\n",
    "        regex = regex.replace(\"[\", \"(\").replace(\"]\", \")\")\n",
    "        print(\"regex after replacing character classes: \", regex)\n",
    "\n",
    "        ############################################################\n",
    "        ############################################################\n",
    "\n",
    "        # replace hyphen with operator \"|\" to separate the range of characters in the character class\n",
    "        # as example: [0-9] will be converted to (0|1|2|3|4|5|6|7|8|9) and so on.\n",
    "        # as example: [a-z] will be converted to (a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z) and so on.\n",
    "        self.postfix = regex[:]\n",
    "        hyphens_count = self.postfix.count(\"-\")\n",
    "        # print(\"hyphens_count: \", hyphens_count)\n",
    "        # print(\"self.postfix: \", len(self.postfix))\n",
    "        for i in range(hyphens_count):\n",
    "            for j in range(len(self.postfix)):\n",
    "                operator = self.postfix[j]\n",
    "                # if (a-z) ==> (a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z)\n",
    "                if operator == \"-\":\n",
    "                    temp = \"\"\n",
    "                    end = ord(self.postfix[j + 1])\n",
    "                    start = ord(self.postfix[j - 1])\n",
    "                    # The line `# print(\"regex[j - 1]: \", self.postfix[j - 1])` is a commented-out\n",
    "                    # print statement in the code. It is not currently active and does not affect the\n",
    "                    # functionality of the code.\n",
    "                    # print(\"start: \", start)\n",
    "                    # print(\"end: \", end)\n",
    "                    # print(\"regex[j]: \", self.postfix)\n",
    "                    # print(\"regex[j - 1]: \", self.postfix[j - 1])\n",
    "                    # print(\"regex[j + 1]: \", self.postfix[j + 1])\n",
    "                    for z in range(int(end - start)):\n",
    "                        temp += \"|\"\n",
    "                        char = chr(start + z + 1)\n",
    "                        temp += char\n",
    "                    self.postfix = self.postfix[0:j] + temp + self.postfix[j + 2 :]\n",
    "                    break\n",
    "        print(\"regex after replacing hyphens with alternation: \", self.postfix)\n",
    "        \n",
    "        # insert . operator between adjacent characters\n",
    "        dots_container = []\n",
    "        start_ops = [\"*\", \")\", \"+\",\"?\"]\n",
    "        end_ops = [\"*\", \"+\",\".\", \")\", \"|\", \"?\"]\n",
    "\n",
    "        for i in range(len(self.postfix) - 1):\n",
    "            if self.postfix[i].isalnum() and (self.postfix[i + 1].isalnum() or self.postfix[i + 1] == \"(\"):\n",
    "                dots_container.append(i)\n",
    "            elif self.postfix[i] in start_ops and self.postfix[i + 1] not in end_ops:\n",
    "                dots_container.append(i)\n",
    "\n",
    "        for i in range(len(dots_container)):\n",
    "            self.postfix = self.postfix[: dots_container[i] + i+ 1] + \".\" + self.postfix[dots_container[i] +i + 1 :]\n",
    "\n",
    "        ############################################################\n",
    "        ############################################################\n",
    "        print(\"regex after inserting . operator: \", self.postfix)\n",
    "\n",
    "        # apply the shunting yard algorithm to convert the infix regular expression to postfix\n",
    "        stack = []\n",
    "        postfix = \"\"\n",
    "        for i in range(len(self.postfix)):\n",
    "            operator = self.postfix[i]\n",
    "            if operator == \"(\":\n",
    "                stack.append(operator)\n",
    "            elif operator == \")\":\n",
    "                while stack[-1] != \"(\":\n",
    "                    postfix += stack.pop()\n",
    "                stack.pop() #! ==> remove the left parenthesis '('\n",
    "            elif operator in operators:\n",
    "                while stack and operators[operator] <= operators[stack[-1]]:\n",
    "                    postfix += stack.pop() \n",
    "                stack.append(operator)\n",
    "            else:\n",
    "                postfix += operator\n",
    "            # print(\"stack: \", stack)\n",
    "            # print(\"postfix: \", postfix)\n",
    "        while stack:\n",
    "            postfix += stack.pop()\n",
    "\n",
    "        # print(\"final postfix: \", postfix)\n",
    "        # return \"a.b?.a.b.\"\n",
    "        return postfix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, label,  transitions=[], parents=[], is_accepting=True,is_starting=False):\n",
    "        self.label = label\n",
    "        self.transitions = []\n",
    "        self.is_starting = is_starting\n",
    "        self.is_accepting = is_accepting\n",
    "        self.parents = parents\n",
    "\n",
    "    def add_transition(self, symbol, state):\n",
    "        # if symbol not in self.transitions:\n",
    "            # self.transitions[symbol] = []\n",
    "        self.transitions.append((symbol, state))\n",
    "        state.parents.append(self)\n",
    "        self.is_accepting = False\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFA:\n",
    "    def __init__(self, start=None, accept=None, postfix=None):\n",
    "        self.start = start\n",
    "        self.accept = accept\n",
    "        if postfix and not start and not accept:\n",
    "            self.nfa = self.construct_nfa(postfix)\n",
    "            self.start = self.nfa.start\n",
    "            self.accept = self.nfa.accept\n",
    "\n",
    "    def get_state_by_label(self, label):\n",
    "        for state in self.get_states():\n",
    "            if state.label == label:\n",
    "                return state\n",
    "\n",
    "    def get_states(self):\n",
    "        states = []\n",
    "        visited = set()\n",
    "        queue = [self.start]\n",
    "        visited.add(self.start)\n",
    "        while queue:\n",
    "            current_state = queue.pop(0)\n",
    "            # print(\"state: \", current_state.label)\n",
    "            # print (\"Transitions of current state: \", [state.label for symbol, state in current_state.transitions])\n",
    "            states.append(current_state)\n",
    "            # print(\"Labels of States: \", [state.label for state in states])\n",
    "            for _,state in current_state.transitions:\n",
    "                if state not in visited:\n",
    "                    queue.append(state)\n",
    "                    visited.add(state)\n",
    "        \n",
    "        states.sort(key=lambda x: x.label)\n",
    "        # print(\"Final Labels of States: \", [state.label for state in states])\n",
    "            \n",
    "        return states\n",
    "\n",
    "    def get_accepting_states(self):\n",
    "        return [state for state in self.get_states() if state.is_accepting]\n",
    "        \n",
    "\n",
    "    # check if one accpeting state is reachable from another accepting state\n",
    "    def is_accepting_state_reachable(self,states):\n",
    "        # print(\"States in is_accepting_state_reachable: \", states)\n",
    "        for state in states:\n",
    "            if state.is_accepting:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_states_by_label(self, labels):\n",
    "        labels = labels.split()\n",
    "        states_by_label = []\n",
    "        for label in labels:\n",
    "            states_by_label.append(self.get_state_by_label(label))\n",
    "        return states_by_label\n",
    "\n",
    "    def get_symbols(self):\n",
    "        symbols = set()\n",
    "        states = self.get_states()\n",
    "        for state in states:\n",
    "            for symbol, _ in state.transitions:\n",
    "                if symbol != \"ε\":\n",
    "                    symbols.add(symbol)\n",
    "        # print(\"Symbols: \", list(symbols))\n",
    "        return list(symbols)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def handle_closure(char, nfa_stack, i):\n",
    "        state_1 = nfa_stack.pop()\n",
    "        start = State(\"S\" + str(i))\n",
    "        accept = State(\"S\" + str(i + 1))\n",
    "        start.add_transition(\"ε\", state_1.start)\n",
    "        start.add_transition(\"ε\", accept)\n",
    "        state_1.accept.add_transition(\"ε\", start)\n",
    "        state_1.accept.add_transition(\"ε\", accept)\n",
    "        nfa_stack.append(NFA(start, accept))\n",
    "        return i + 2 \n",
    "        \n",
    "    def handle_alternation(char, nfa_stack, i):\n",
    "        state_2 = nfa_stack.pop()\n",
    "        state_1 = nfa_stack.pop()\n",
    "        start = State(\"S\" + str(i))\n",
    "        accept = State(\"S\" + str(i + 1))\n",
    "        start.add_transition(\"ε\", state_1.start)\n",
    "        start.add_transition(\"ε\", state_2.start)\n",
    "        state_1.accept.add_transition(\"ε\", accept)\n",
    "        state_2.accept.add_transition(\"ε\", accept)\n",
    "        nfa_stack.append(NFA(start, accept))\n",
    "        return i + 2\n",
    "        \n",
    "        \n",
    "    def handle_concatenation(char, nfa_stack, i):\n",
    "        state_2 = nfa_stack.pop()\n",
    "        state_1 = nfa_stack.pop()                \n",
    "        state_1.accept.add_transition(\"ε\", state_2.start)\n",
    "        nfa_stack.append(NFA(state_1.start, state_2.accept))\n",
    "        return i \n",
    "        \n",
    "    def handle_positive_closure(char, nfa_stack, i):\n",
    "        state_1 = nfa_stack.pop()\n",
    "        start = State(\"S\" + str(i))\n",
    "        accept = State(\"S\" + str(i + 1))\n",
    "        start.add_transition(\"ε\", state_1.start)\n",
    "        state_1.accept.add_transition(\"ε\", start)\n",
    "        state_1.accept.add_transition(\"ε\", accept)\n",
    "        nfa_stack.append(NFA(start, accept))\n",
    "        return i + 2\n",
    "        \n",
    "    def handle_optional(char, nfa_stack, i):\n",
    "        state_1 = nfa_stack.pop()\n",
    "        start = State(\"S\" + str(i))\n",
    "        accept = State(\"S\" + str(i + 1))\n",
    "        start.add_transition(\"ε\", state_1.start)\n",
    "        start.add_transition(\"ε\", accept)\n",
    "        state_1.accept.add_transition(\"ε\", accept)\n",
    "        nfa_stack.append(NFA(start, accept))\n",
    "        return i + 2\n",
    "        \n",
    "    def handle_alpha_numeric(char, nfa_stack, i):\n",
    "        start = State(\"S\" + str(i))\n",
    "        accept = State(\"S\" + str(i + 1))\n",
    "        start.add_transition(char, accept)\n",
    "        nfa_stack.append(NFA(start, accept))\n",
    "        return i + 2\n",
    "\n",
    "    def construct_nfa(self, postfix):\n",
    "        nfa_stack = []\n",
    "        i = 1\n",
    "        for char in postfix:\n",
    "            if char == \"*\":\n",
    "                i = NFA.handle_closure(char, nfa_stack, i)\n",
    "\n",
    "            elif char == \"|\":\n",
    "                i = NFA.handle_alternation(char, nfa_stack, i)\n",
    "            elif char == \".\":\n",
    "                i = NFA.handle_concatenation(char, nfa_stack, i)\n",
    "                \n",
    "            elif char == \"+\":\n",
    "                i = NFA.handle_positive_closure(char, nfa_stack, i)\n",
    "            \n",
    "            elif char == \"?\":\n",
    "                i = NFA.handle_optional(char, nfa_stack, i)\n",
    "            else:\n",
    "                i = NFA.handle_alpha_numeric(char, nfa_stack, i)\n",
    "\n",
    "        return nfa_stack.pop()\n",
    "\n",
    "    def to_graph(self):\n",
    "\n",
    "        states = {}\n",
    "        for state in self.get_states():\n",
    "            state_graph = {\n",
    "                \"isTerminatingState\": state.is_accepting,\n",
    "            }\n",
    "            for symbol, transition in state.transitions:\n",
    "                if symbol not in state_graph:\n",
    "                    state_graph[symbol] = transition.label\n",
    "                else:\n",
    "                    state_graph[symbol] += \",\" + transition.label\n",
    "            states[state.label] = state_graph\n",
    "              \n",
    "        # make a json object of the NFA graph\n",
    "        dump_json({\"startingState\": self.start.label, **states}, \"output/nfa/nfa.json\")\n",
    "            \n",
    "            \n",
    "        return {\n",
    "            \"startingState\": self.start.label,\n",
    "            **states,\n",
    "        }\n",
    "\n",
    "    def visualize(self, name=\"output/nfa/nfa.gv\", view=False,pattern=None):\n",
    "        nfa_graph = self.to_graph()\n",
    "        graph = graphviz.Digraph(name=\"NFA\",engine=\"dot\")\n",
    "\n",
    "        for state, transitions in nfa_graph.items():\n",
    "            if state == \"startingState\":\n",
    "                graph.node(\"\", shape=\"none\")\n",
    "                graph.edge(\"\", transitions)\n",
    "                continue\n",
    "            if transitions[\"isTerminatingState\"]:\n",
    "                graph.node(state, shape=\"doublecircle\")\n",
    "            else:\n",
    "                graph.node(state, shape=\"circle\")\n",
    "                \n",
    "                \n",
    "            for symbol, next_state in transitions.items():\n",
    "                if symbol == \"isTerminatingState\":\n",
    "                    continue\n",
    "                children = next_state.split(\",\")\n",
    "                for child in children:\n",
    "                    graph.edge(state, child, label=symbol)\n",
    "\n",
    "        graph.format = \"png\"\n",
    "        graph.attr(rankdir=\"LR\",label=\"NFA's pattern: \" + pattern, fontname='bold')\n",
    "        graph.render(name, view=view)\n",
    "\n",
    "        return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "class DFA:\n",
    "    def __init__(self, nfa):\n",
    "        self.nfa = nfa\n",
    "        self.dfa_states = self.construct_dfa()\n",
    "        \n",
    "    def get_symbols(self):\n",
    "        return self.nfa.get_symbols()\n",
    "    def get_states(self):\n",
    "        return self.nfa.get_states()\n",
    "\n",
    "    def _epsilon_closure(self, states):\n",
    "        closure = set(states)\n",
    "        stack = list(states)\n",
    "        while stack:\n",
    "            current_state = stack.pop()\n",
    "            for symbol, next_state in current_state.transitions:\n",
    "                if symbol == \"ε\" and next_state not in closure:\n",
    "                    stack.append(next_state)\n",
    "                    closure.add(next_state)\n",
    "\n",
    "        closure = list(closure)\n",
    "        closure.sort(key=lambda x: x.label)\n",
    "\n",
    "        closure = \" \".join([state.label for state in closure])\n",
    "        # print(\"closure: \", closure)\n",
    "        return closure\n",
    "\n",
    "    def _move(self, state, symbol):\n",
    "        next_states = set()\n",
    "\n",
    "        states = state.split()  \n",
    "        states_list = []\n",
    "        for label in states:\n",
    "            state = self.nfa.get_state_by_label(label)\n",
    "            # print(\"State in Move!: \", state.label)\n",
    "            states_list.append(state)\n",
    "        for state in states_list:\n",
    "            for s, next_state in state.transitions:\n",
    "                if s == symbol:\n",
    "                    next_states.add(next_state)\n",
    "        return next_states\n",
    "    \n",
    "    def construct_dfa(self):\n",
    "        dfa_transitions = {}\n",
    "        symbols = self.nfa.get_symbols()\n",
    "        dfa_start = self._epsilon_closure([self.nfa.start])\n",
    "        # print(\"First Epsilon Closure: \", dfa_start)\n",
    "        self.dfa_states = {'startingState': dfa_start}\n",
    "\n",
    "        queue = deque([dfa_start])\n",
    "        visited = set([dfa_start])\n",
    "\n",
    "        while queue:\n",
    "            current_state = queue.popleft()\n",
    "            # print(\"current_state: \", current_state)\n",
    "            for symbol in symbols:\n",
    "                next_moves = self._move(current_state, symbol)\n",
    "                if not next_moves:\n",
    "                    continue\n",
    "                next_states = self._epsilon_closure(next_moves)\n",
    "                # print(\"Current State: \", current_state)\n",
    "                # print(\"Symbol: \", symbol)\n",
    "                # print(\"Moves: \", [state.label for state in next_moves])\n",
    "                # print(\"Epsilon Closures: \", next_states)\n",
    "                if next_states == \" \" or next_states == \"\":\n",
    "                    continue\n",
    "                if next_states not in visited:\n",
    "                    queue.append(next_states)\n",
    "                    visited.add(next_states)\n",
    "                self.dfa_states.setdefault(current_state, {})[symbol] = next_states\n",
    "            states_by_label = self.nfa.get_states_by_label(current_state)\n",
    "            self.dfa_states.setdefault(current_state, {})[\"isTerminatingState\"] = self.nfa.is_accepting_state_reachable(states_by_label)\n",
    "\n",
    "        # TODO complete the implementation after Eid break :)\n",
    "\n",
    "        return self.dfa_states\n",
    "        \n",
    "\n",
    "        \n",
    "    def visualize(self, name=\"output/dfa/dfa.gv\", view=True,pattern=None):\n",
    "        graph = graphviz.Digraph(name=\"DFA\", engine=\"dot\")\n",
    "        \n",
    "        for state, transitions in self.dfa_states.items():\n",
    "    \n",
    "            if state == \"startingState\":\n",
    "                graph.node(\"\", shape=\"none\")\n",
    "                graph.edge(\"\", transitions)\n",
    "                continue\n",
    "            if transitions[\"isTerminatingState\"]:\n",
    "                graph.node(state, shape=\"doublecircle\")\n",
    "            else:\n",
    "                graph.node(state, shape=\"circle\")\n",
    "                \n",
    "                \n",
    "            for symbol, next_state in transitions.items():\n",
    "                if symbol == \"isTerminatingState\":\n",
    "                    continue\n",
    "                children = next_state.split(\",\")\n",
    "                for child in children:\n",
    "                    graph.edge(state, child, label=symbol)\n",
    "                    \n",
    "        graph.format = \"png\"\n",
    "        graph.attr(rankdir=\"LR\",label=\"NFA's pattern: \" + pattern, fontname='bold')\n",
    "        graph.render(name, view=view)\n",
    "        \n",
    "\n",
    "\n",
    "    def to_graph(self):\n",
    "        dump_json({**self.dfa_states}, \"output/dfa/dfa.json\")\n",
    "        return self.dfa_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIN_DFA:\n",
    "    def __init__(self, dfa):\n",
    "        self.dfa = dfa\n",
    "        self.min_dfa_states = self.minimize()\n",
    "        \n",
    "\n",
    "    def minimize(self):\n",
    "\n",
    "        states = self.dfa.to_graph()\n",
    "        symbols = self.dfa.get_symbols()\n",
    "        # print(\"############################################ Min Dfa #########################################\")\n",
    "        # print(\"Symbols: \", symbols)\n",
    "        # print(\"States: \", states)\n",
    "        # for key in list(states.keys())[1:]:\n",
    "        #     print(f\"{key}: {states[key]}\")\n",
    "        states.pop(\"startingState\")\n",
    "\n",
    "        #! Step 1: Split the states into two groups\n",
    "        # Group 1: Accepting states\n",
    "        # Group 2: Non-accepting states\n",
    "        group1 = []\n",
    "        group2 = []\n",
    "        all_groups = []\n",
    "\n",
    "        # for key in list(states.keys())[1:]:\n",
    "        #     if states[key][\"isTerminatingState\"]:\n",
    "        #         group1.append(states[key])\n",
    "        #     else:\n",
    "        #         group2.append(states[key])\n",
    "        for key, value in states.items():\n",
    "            if value[\"isTerminatingState\"]:\n",
    "                group1.append({key: value})\n",
    "            else:\n",
    "                group2.append({key: value})\n",
    "\n",
    "        all_groups.append(group1)\n",
    "        all_groups.append(group2)\n",
    "\n",
    "        # print(\"Group1: \", group1)\n",
    "        # print(\"Group2: \", group2)\n",
    "        # print(\"All Groups: \", all_groups)\n",
    "        #! [[{'S2 S3 S5 S6': {'b': 'S4 S6', 'isTerminatingState': True}}, {'S4 S6': {'isTerminatingState': True}}], [{'S1': {'a': 'S2 S3 S5 S6', 'isTerminatingState': False}}]]\n",
    "\n",
    "        #! #############    Step 2: Split the groups until no further splits are possible  #############\n",
    "        #! for each group split the group into subgroups based on the transitions of each state ,\n",
    "        #! if there is a transition to a state in another group then split the group\n",
    "        symbol_groups = {}\n",
    "        i = -1\n",
    "        length = len(all_groups)\n",
    "        while i < length:\n",
    "            i += 1\n",
    "            if i < 0:\n",
    "                i = 0\n",
    "            if i >= len(all_groups):\n",
    "                break    \n",
    "            # print(\"\\n\")\n",
    "            # print(\"\\n\")\n",
    "            # print(\"i ==> \",i)\n",
    "            # print(\"length ==> \",length)\n",
    "            current_group = all_groups[i]\n",
    "            # print(\"Current Group: \",current_group)\n",
    "            \n",
    "            isSplitted = False\n",
    "            if len(current_group) < 2:\n",
    "                continue\n",
    "            for symbol in symbols:\n",
    "                if isSplitted:\n",
    "                    break\n",
    "                symbol_groups = {}\n",
    "                for j in range(len(current_group)):\n",
    "                    current_state = current_group[j]\n",
    "                    for key, value in current_state.items():\n",
    "                            if symbol in value:\n",
    "                                for k in range(len(all_groups)):\n",
    "                                    for state in all_groups[k]:\n",
    "                                        if (value[symbol] in state):\n",
    "                                            # print(symbol,current_state, \" is looking in group \",k)\n",
    "                                            if symbol not in symbol_groups:\n",
    "                                                symbol_groups[symbol] = {}\n",
    "                                            if k not in symbol_groups[symbol]:\n",
    "                                                symbol_groups[symbol][k] = [current_state]\n",
    "                                            else:\n",
    "                                                symbol_groups[symbol][k].append(current_state)\n",
    "                                            # print(symbol_groups)\n",
    "\n",
    "                            else:\n",
    "                                # print(symbol,current_state,\" don't have\")\n",
    "                                k = \"none\"\n",
    "                                if symbol not in symbol_groups:\n",
    "                                    symbol_groups[symbol] = {}\n",
    "                                if k not in symbol_groups[symbol]:\n",
    "                                    symbol_groups[symbol][k] = [current_state]\n",
    "                                else:\n",
    "                                    symbol_groups[symbol][k].append(current_state)\n",
    "                                # print(symbol_groups)    \n",
    "                \n",
    "                for key, value in symbol_groups.items():\n",
    "                    # print(\"Key: \", key, \" value: \", value)\n",
    "                    # Check if the symbol is present in multiple groups\n",
    "                    if len(value) > 1:\n",
    "                        all_groups[i] = []\n",
    "                        isSplitted = True\n",
    "                        # Extract states associated with each group\n",
    "                        for group_index, states in value.items():\n",
    "                            # print(\"group_index\",group_index)\n",
    "                            # print(\"states: \",states)\n",
    "                            all_groups.append(states)\n",
    "                            # Remove original group from all_groups\n",
    "                        # Insert the extracted states into all_groups and reset i to 0\n",
    "                        \n",
    "                        i = -1\n",
    "                        break\n",
    "                # print(\"All groups: \", all_groups) \n",
    "                length = len(all_groups)       \n",
    "        # Remove empty groups from all_groups            \n",
    "        all_groups = [group for group in all_groups if group]     \n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "        #! Step 3: Create the minimized DFA\n",
    "        self.min_dfa_states = self.create_minimized_states(all_groups)\n",
    "\n",
    "        return self.min_dfa_states\n",
    "\n",
    "    def create_minimized_states(self, groups):\n",
    "        # print(\"########################################################################################\")\n",
    "        # print(\"\\n\\n\")\n",
    "        # print(\"Groups in MIN_DFA: \", groups)\n",
    "        # print(\"########################################################################################\")\n",
    "        # print(\"\\n\\n\")\n",
    "        #![[{'S2 S3 S5 S6': {'b': 'S4 S6', 'isTerminatingState': True}}], [{'S4 S6': {'isTerminatingState': True}}], [{'S1': {'a': 'S2 S3 S5 S6', 'isTerminatingState': False}}]]\n",
    "        condensed_states = {}\n",
    "        # print(\"Groups in MIN_DFA: \", groups)\n",
    "        \n",
    "        for idx, group in enumerate(groups,start=1):\n",
    "            for state in group:\n",
    "                # for all states in the group, update the name of the state to the index of the group\n",
    "                for key, value in state.items():\n",
    "                    condensed_states[key] = str(idx)\n",
    "        \n",
    "        # print(\"condensed_states: \",condensed_states)\n",
    "        new_groups = {'startingState': 1}\n",
    "    \n",
    "        for idx, group in enumerate(groups,start=1):\n",
    "            # iterate over each state in the group    \n",
    "            for state in group:\n",
    "                # iterate over each symbol in the state\n",
    "                for key, value in state.items():\n",
    "                    # iterate over each symbol in the state\n",
    "                    for symbol, next_state in value.items():\n",
    "                        if symbol!='isTerminatingState':\n",
    "                            # print(next_state)\n",
    "                            # check if the next state is in the condensed states , then update the value of the state\n",
    "                            if next_state in condensed_states:\n",
    "                                value[symbol] = str(condensed_states[next_state])\n",
    "                                new_groups[str(idx)] = value\n",
    "                                \n",
    "        for state, group_index in condensed_states.items():\n",
    "            if group_index not in new_groups:\n",
    "                new_groups[group_index] = {'isTerminatingState': True}\n",
    "        # print(\"New Groups in DFA: \", new_groups)\n",
    "        #! New Groups in DFA: {'startingState': 1, '1': {'b': '2', 'isTerminatingState': True}, '3': {'a': '1', 'isTerminatingState': False}}            \n",
    "        return new_groups\n",
    "\n",
    "    def to_graph(self):\n",
    "        return self.min_dfa_states\n",
    "\n",
    "    def visualize(self, name=\"output/min-dfa/min-dfa.gv\", view=True,pattern=None):\n",
    "        graph = graphviz.Digraph(name=\"MIN_DFA\", engine=\"dot\")\n",
    "        # print(\"Minimized DFA States: \", self.min_dfa_states)\n",
    "        #! Minimized DFA States:  {'startingState': 1, '1': {'b': '2', 'isTerminatingState': True}, '3': {'a': '1', 'isTerminatingState': False}, '2': {'b': '2', 'isTerminatingState': True}}\n",
    "        for state, transitions in self.min_dfa_states.items():\n",
    "            if state == \"startingState\":\n",
    "                # graph.node(\"\", shape=\"none\")\n",
    "                # graph.edge(\"\", \"1\")\n",
    "                continue\n",
    "                \n",
    "            if transitions[\"isTerminatingState\"]:\n",
    "                graph.node(state, shape=\"doublecircle\")\n",
    "            else:\n",
    "                graph.node(state, shape=\"circle\")\n",
    "            \n",
    "            \n",
    "            for symbol, next_state in transitions.items():\n",
    "                if symbol == \"isTerminatingState\":\n",
    "                    continue\n",
    "                    \n",
    "                children_states = next_state.split(\",\")\n",
    "                for child in children_states:\n",
    "                    graph.edge(state, child, label=symbol)\n",
    "                \n",
    "        graph._format = \"png\"\n",
    "        graph.attr(rankdir=\"LR\",label=\"NFA's pattern: \" + pattern, fontname='bold')\n",
    "        graph.render(name, view=view)\n",
    "        return graph\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegexProcessor:\n",
    "    def __init__(self, regex):\n",
    "        self.regex = regex\n",
    "\n",
    "    def process(self, idx):\n",
    "        create_directory(\"output/nfa\")\n",
    "        create_directory(\"output/dfa\")\n",
    "        create_directory(\"output/min-dfa\")\n",
    "\n",
    "        # print(f\"\\033[1;33m{'#' * 30}\\n#     Regex Processor     #\\n{'#' * 30}\\033[0m\\n\")\n",
    "        # print(f\"Regex: {self.regex}\\n\")\n",
    "\n",
    "        # Validate the regex\n",
    "        regex_validator = RegexValidator(self.regex)\n",
    "\n",
    "        if not regex_validator.validate():\n",
    "            return \"Error\", None, None\n",
    "\n",
    "        # Convert the regex to postfix notation\n",
    "        postfix_regex = regex_validator.post_validate()\n",
    "        print(f\"\\033[1;32mPostfix notation: {postfix_regex}\\n\\033[0m\")\n",
    "\n",
    "        # Convert the regex to an NFA\n",
    "        nfa = NFA(postfix=postfix_regex)\n",
    "        print(f\"\\033[1;36mNFA: {nfa.to_graph()}\\n\\033[0m\")\n",
    "        nfa.visualize(name=f\"output/nfa/nfa_{idx}.gv\", view=False,pattern=self.regex)\n",
    "\n",
    "        # Convert the NFA to a DFA\n",
    "        dfa = DFA(nfa)\n",
    "        print(f\"\\033[1;36mDFA: {dfa.to_graph()}\\n\\033[0m\")\n",
    "        dfa.visualize(name=f\"output/dfa/dfa_{idx}.gv\", view=False,pattern=self.regex)\n",
    "\n",
    "        # Minimize the DFA\n",
    "        minimized_dfa = MIN_DFA(dfa)\n",
    "        print(f\"\\033[1;36mMin-DFA: {minimized_dfa.to_graph()}\\n\\033[0m\")\n",
    "        minimized_dfa.visualize(name=f\"output/min-dfa/min-dfa_{idx}.gv\", view=False,pattern=self.regex)\n",
    "\n",
    "        return \"Success\", nfa, minimized_dfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 1     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: ab[ce-df]\n",
      "Invalid regex: ab[ce-df]\n",
      "Invalid regex\n",
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 2     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: ab[ce-df\n",
      "Invalid regular expression: unmatched brackets\n",
      "Invalid regex\n",
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 3     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: ab?ab\n",
      "regex after replacing character classes:  ab?ab\n",
      "regex after replacing hyphens with alternation:  ab?ab\n",
      "regex after inserting . operator:  a.b?.a.b\n",
      "\u001b[1;32mPostfix notation: ab?.a.b.\n",
      "\u001b[0m\n",
      "\u001b[1;36mNFA: {'startingState': 'S1', 'S1': {'isTerminatingState': False, 'a': 'S2'}, 'S10': {'isTerminatingState': True}, 'S2': {'isTerminatingState': False, 'ε': 'S5'}, 'S3': {'isTerminatingState': False, 'b': 'S4'}, 'S4': {'isTerminatingState': False, 'ε': 'S6'}, 'S5': {'isTerminatingState': False, 'ε': 'S3,S6'}, 'S6': {'isTerminatingState': False, 'ε': 'S7'}, 'S7': {'isTerminatingState': False, 'a': 'S8'}, 'S8': {'isTerminatingState': False, 'ε': 'S9'}, 'S9': {'isTerminatingState': False, 'b': 'S10'}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mDFA: {'startingState': 'S1', 'S1': {'a': 'S2 S3 S5 S6 S7', 'isTerminatingState': False}, 'S2 S3 S5 S6 S7': {'b': 'S4 S6 S7', 'a': 'S8 S9', 'isTerminatingState': False}, 'S4 S6 S7': {'a': 'S8 S9', 'isTerminatingState': False}, 'S8 S9': {'b': 'S10', 'isTerminatingState': False}, 'S10': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mMin-DFA: {'startingState': 1, '2': {'b': '5', 'a': '3', 'isTerminatingState': False}, '3': {'b': '1', 'isTerminatingState': False}, '4': {'a': '2', 'isTerminatingState': False}, '5': {'a': '3', 'isTerminatingState': False}, '1': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "Processing successful!\n",
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 4     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: a[a-z0-1]\n",
      "regex after replacing character classes:  a(a-z|0-1)\n",
      "regex after replacing hyphens with alternation:  a(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|0|1)\n",
      "regex after inserting . operator:  a.(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|0|1)\n",
      "\u001b[1;32mPostfix notation: aab|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|0|1|.\n",
      "\u001b[0m\n",
      "\u001b[1;36mNFA: {'startingState': 'S1', 'S1': {'isTerminatingState': False, 'a': 'S2'}, 'S10': {'isTerminatingState': False, 'ε': 'S12'}, 'S100': {'isTerminatingState': False, 'ε': 'S104'}, 'S101': {'isTerminatingState': False, 'z': 'S102'}, 'S102': {'isTerminatingState': False, 'ε': 'S104'}, 'S103': {'isTerminatingState': False, 'ε': 'S99,S101'}, 'S104': {'isTerminatingState': False, 'ε': 'S108'}, 'S105': {'isTerminatingState': False, '0': 'S106'}, 'S106': {'isTerminatingState': False, 'ε': 'S108'}, 'S107': {'isTerminatingState': False, 'ε': 'S103,S105'}, 'S108': {'isTerminatingState': False, 'ε': 'S112'}, 'S109': {'isTerminatingState': False, '1': 'S110'}, 'S11': {'isTerminatingState': False, 'ε': 'S7,S9'}, 'S110': {'isTerminatingState': False, 'ε': 'S112'}, 'S111': {'isTerminatingState': False, 'ε': 'S107,S109'}, 'S112': {'isTerminatingState': True}, 'S12': {'isTerminatingState': False, 'ε': 'S16'}, 'S13': {'isTerminatingState': False, 'd': 'S14'}, 'S14': {'isTerminatingState': False, 'ε': 'S16'}, 'S15': {'isTerminatingState': False, 'ε': 'S11,S13'}, 'S16': {'isTerminatingState': False, 'ε': 'S20'}, 'S17': {'isTerminatingState': False, 'e': 'S18'}, 'S18': {'isTerminatingState': False, 'ε': 'S20'}, 'S19': {'isTerminatingState': False, 'ε': 'S15,S17'}, 'S2': {'isTerminatingState': False, 'ε': 'S111'}, 'S20': {'isTerminatingState': False, 'ε': 'S24'}, 'S21': {'isTerminatingState': False, 'f': 'S22'}, 'S22': {'isTerminatingState': False, 'ε': 'S24'}, 'S23': {'isTerminatingState': False, 'ε': 'S19,S21'}, 'S24': {'isTerminatingState': False, 'ε': 'S28'}, 'S25': {'isTerminatingState': False, 'g': 'S26'}, 'S26': {'isTerminatingState': False, 'ε': 'S28'}, 'S27': {'isTerminatingState': False, 'ε': 'S23,S25'}, 'S28': {'isTerminatingState': False, 'ε': 'S32'}, 'S29': {'isTerminatingState': False, 'h': 'S30'}, 'S3': {'isTerminatingState': False, 'a': 'S4'}, 'S30': {'isTerminatingState': False, 'ε': 'S32'}, 'S31': {'isTerminatingState': False, 'ε': 'S27,S29'}, 'S32': {'isTerminatingState': False, 'ε': 'S36'}, 'S33': {'isTerminatingState': False, 'i': 'S34'}, 'S34': {'isTerminatingState': False, 'ε': 'S36'}, 'S35': {'isTerminatingState': False, 'ε': 'S31,S33'}, 'S36': {'isTerminatingState': False, 'ε': 'S40'}, 'S37': {'isTerminatingState': False, 'j': 'S38'}, 'S38': {'isTerminatingState': False, 'ε': 'S40'}, 'S39': {'isTerminatingState': False, 'ε': 'S35,S37'}, 'S4': {'isTerminatingState': False, 'ε': 'S8'}, 'S40': {'isTerminatingState': False, 'ε': 'S44'}, 'S41': {'isTerminatingState': False, 'k': 'S42'}, 'S42': {'isTerminatingState': False, 'ε': 'S44'}, 'S43': {'isTerminatingState': False, 'ε': 'S39,S41'}, 'S44': {'isTerminatingState': False, 'ε': 'S48'}, 'S45': {'isTerminatingState': False, 'l': 'S46'}, 'S46': {'isTerminatingState': False, 'ε': 'S48'}, 'S47': {'isTerminatingState': False, 'ε': 'S43,S45'}, 'S48': {'isTerminatingState': False, 'ε': 'S52'}, 'S49': {'isTerminatingState': False, 'm': 'S50'}, 'S5': {'isTerminatingState': False, 'b': 'S6'}, 'S50': {'isTerminatingState': False, 'ε': 'S52'}, 'S51': {'isTerminatingState': False, 'ε': 'S47,S49'}, 'S52': {'isTerminatingState': False, 'ε': 'S56'}, 'S53': {'isTerminatingState': False, 'n': 'S54'}, 'S54': {'isTerminatingState': False, 'ε': 'S56'}, 'S55': {'isTerminatingState': False, 'ε': 'S51,S53'}, 'S56': {'isTerminatingState': False, 'ε': 'S60'}, 'S57': {'isTerminatingState': False, 'o': 'S58'}, 'S58': {'isTerminatingState': False, 'ε': 'S60'}, 'S59': {'isTerminatingState': False, 'ε': 'S55,S57'}, 'S6': {'isTerminatingState': False, 'ε': 'S8'}, 'S60': {'isTerminatingState': False, 'ε': 'S64'}, 'S61': {'isTerminatingState': False, 'p': 'S62'}, 'S62': {'isTerminatingState': False, 'ε': 'S64'}, 'S63': {'isTerminatingState': False, 'ε': 'S59,S61'}, 'S64': {'isTerminatingState': False, 'ε': 'S68'}, 'S65': {'isTerminatingState': False, 'q': 'S66'}, 'S66': {'isTerminatingState': False, 'ε': 'S68'}, 'S67': {'isTerminatingState': False, 'ε': 'S63,S65'}, 'S68': {'isTerminatingState': False, 'ε': 'S72'}, 'S69': {'isTerminatingState': False, 'r': 'S70'}, 'S7': {'isTerminatingState': False, 'ε': 'S3,S5'}, 'S70': {'isTerminatingState': False, 'ε': 'S72'}, 'S71': {'isTerminatingState': False, 'ε': 'S67,S69'}, 'S72': {'isTerminatingState': False, 'ε': 'S76'}, 'S73': {'isTerminatingState': False, 's': 'S74'}, 'S74': {'isTerminatingState': False, 'ε': 'S76'}, 'S75': {'isTerminatingState': False, 'ε': 'S71,S73'}, 'S76': {'isTerminatingState': False, 'ε': 'S80'}, 'S77': {'isTerminatingState': False, 't': 'S78'}, 'S78': {'isTerminatingState': False, 'ε': 'S80'}, 'S79': {'isTerminatingState': False, 'ε': 'S75,S77'}, 'S8': {'isTerminatingState': False, 'ε': 'S12'}, 'S80': {'isTerminatingState': False, 'ε': 'S84'}, 'S81': {'isTerminatingState': False, 'u': 'S82'}, 'S82': {'isTerminatingState': False, 'ε': 'S84'}, 'S83': {'isTerminatingState': False, 'ε': 'S79,S81'}, 'S84': {'isTerminatingState': False, 'ε': 'S88'}, 'S85': {'isTerminatingState': False, 'v': 'S86'}, 'S86': {'isTerminatingState': False, 'ε': 'S88'}, 'S87': {'isTerminatingState': False, 'ε': 'S83,S85'}, 'S88': {'isTerminatingState': False, 'ε': 'S92'}, 'S89': {'isTerminatingState': False, 'w': 'S90'}, 'S9': {'isTerminatingState': False, 'c': 'S10'}, 'S90': {'isTerminatingState': False, 'ε': 'S92'}, 'S91': {'isTerminatingState': False, 'ε': 'S87,S89'}, 'S92': {'isTerminatingState': False, 'ε': 'S96'}, 'S93': {'isTerminatingState': False, 'x': 'S94'}, 'S94': {'isTerminatingState': False, 'ε': 'S96'}, 'S95': {'isTerminatingState': False, 'ε': 'S91,S93'}, 'S96': {'isTerminatingState': False, 'ε': 'S100'}, 'S97': {'isTerminatingState': False, 'y': 'S98'}, 'S98': {'isTerminatingState': False, 'ε': 'S100'}, 'S99': {'isTerminatingState': False, 'ε': 'S95,S97'}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mDFA: {'startingState': 'S1', 'S1': {'a': 'S101 S103 S105 S107 S109 S11 S111 S13 S15 S17 S19 S2 S21 S23 S25 S27 S29 S3 S31 S33 S35 S37 S39 S41 S43 S45 S47 S49 S5 S51 S53 S55 S57 S59 S61 S63 S65 S67 S69 S7 S71 S73 S75 S77 S79 S81 S83 S85 S87 S89 S9 S91 S93 S95 S97 S99', 'isTerminatingState': False}, 'S101 S103 S105 S107 S109 S11 S111 S13 S15 S17 S19 S2 S21 S23 S25 S27 S29 S3 S31 S33 S35 S37 S39 S41 S43 S45 S47 S49 S5 S51 S53 S55 S57 S59 S61 S63 S65 S67 S69 S7 S71 S73 S75 S77 S79 S81 S83 S85 S87 S89 S9 S91 S93 S95 S97 S99': {'r': 'S100 S104 S108 S112 S70 S72 S76 S80 S84 S88 S92 S96', 'j': 'S100 S104 S108 S112 S38 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'w': 'S100 S104 S108 S112 S90 S92 S96', 'g': 'S100 S104 S108 S112 S26 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'm': 'S100 S104 S108 S112 S50 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'v': 'S100 S104 S108 S112 S86 S88 S92 S96', 'z': 'S102 S104 S108 S112', 's': 'S100 S104 S108 S112 S74 S76 S80 S84 S88 S92 S96', 'd': 'S100 S104 S108 S112 S14 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'b': 'S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S6 S60 S64 S68 S72 S76 S8 S80 S84 S88 S92 S96', 'c': 'S10 S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'x': 'S100 S104 S108 S112 S94 S96', 'u': 'S100 S104 S108 S112 S82 S84 S88 S92 S96', 'n': 'S100 S104 S108 S112 S54 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'f': 'S100 S104 S108 S112 S22 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'e': 'S100 S104 S108 S112 S18 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', '1': 'S110 S112', '0': 'S106 S108 S112', 'p': 'S100 S104 S108 S112 S62 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'o': 'S100 S104 S108 S112 S58 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'h': 'S100 S104 S108 S112 S30 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'l': 'S100 S104 S108 S112 S46 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 't': 'S100 S104 S108 S112 S78 S80 S84 S88 S92 S96', 'y': 'S100 S104 S108 S112 S98', 'i': 'S100 S104 S108 S112 S34 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'a': 'S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S4 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S8 S80 S84 S88 S92 S96', 'q': 'S100 S104 S108 S112 S66 S68 S72 S76 S80 S84 S88 S92 S96', 'k': 'S100 S104 S108 S112 S42 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96', 'isTerminatingState': False}, 'S100 S104 S108 S112 S70 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S38 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S90 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S26 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S50 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S86 S88 S92 S96': {'isTerminatingState': True}, 'S102 S104 S108 S112': {'isTerminatingState': True}, 'S100 S104 S108 S112 S74 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S14 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S6 S60 S64 S68 S72 S76 S8 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S10 S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S94 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S82 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S54 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S22 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S18 S20 S24 S28 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S110 S112': {'isTerminatingState': True}, 'S106 S108 S112': {'isTerminatingState': True}, 'S100 S104 S108 S112 S62 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S58 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S30 S32 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S46 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S78 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S98': {'isTerminatingState': True}, 'S100 S104 S108 S112 S34 S36 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S12 S16 S20 S24 S28 S32 S36 S4 S40 S44 S48 S52 S56 S60 S64 S68 S72 S76 S8 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S66 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}, 'S100 S104 S108 S112 S42 S44 S48 S52 S56 S60 S64 S68 S72 S76 S80 S84 S88 S92 S96': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mMin-DFA: {'startingState': 1, '2': {'a': '3', 'isTerminatingState': False}, '3': {'r': '1', 'j': '1', 'w': '1', 'g': '1', 'm': '1', 'v': '1', 'z': '1', 's': '1', 'd': '1', 'b': '1', 'c': '1', 'x': '1', 'u': '1', 'n': '1', 'f': '1', 'e': '1', '1': '1', '0': '1', 'p': '1', 'o': '1', 'h': '1', 'l': '1', 't': '1', 'y': '1', 'i': '1', 'a': '1', 'q': '1', 'k': '1', 'isTerminatingState': False}, '1': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "Processing successful!\n",
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 5     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: abb+a?(a|b)\n",
      "regex after replacing character classes:  abb+a?(a|b)\n",
      "regex after replacing hyphens with alternation:  abb+a?(a|b)\n",
      "regex after inserting . operator:  a.b.b+.a?.(a|b)\n",
      "\u001b[1;32mPostfix notation: ab.b+.a?.ab|.\n",
      "\u001b[0m\n",
      "\u001b[1;36mNFA: {'startingState': 'S1', 'S1': {'isTerminatingState': False, 'a': 'S2'}, 'S10': {'isTerminatingState': False, 'ε': 'S12'}, 'S11': {'isTerminatingState': False, 'ε': 'S9,S12'}, 'S12': {'isTerminatingState': False, 'ε': 'S17'}, 'S13': {'isTerminatingState': False, 'a': 'S14'}, 'S14': {'isTerminatingState': False, 'ε': 'S18'}, 'S15': {'isTerminatingState': False, 'b': 'S16'}, 'S16': {'isTerminatingState': False, 'ε': 'S18'}, 'S17': {'isTerminatingState': False, 'ε': 'S13,S15'}, 'S18': {'isTerminatingState': True}, 'S2': {'isTerminatingState': False, 'ε': 'S3'}, 'S3': {'isTerminatingState': False, 'b': 'S4'}, 'S4': {'isTerminatingState': False, 'ε': 'S7'}, 'S5': {'isTerminatingState': False, 'b': 'S6'}, 'S6': {'isTerminatingState': False, 'ε': 'S7,S8'}, 'S7': {'isTerminatingState': False, 'ε': 'S5'}, 'S8': {'isTerminatingState': False, 'ε': 'S11'}, 'S9': {'isTerminatingState': False, 'a': 'S10'}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mDFA: {'startingState': 'S1', 'S1': {'a': 'S2 S3', 'isTerminatingState': False}, 'S2 S3': {'b': 'S4 S5 S7', 'isTerminatingState': False}, 'S4 S5 S7': {'b': 'S11 S12 S13 S15 S17 S5 S6 S7 S8 S9', 'isTerminatingState': False}, 'S11 S12 S13 S15 S17 S5 S6 S7 S8 S9': {'b': 'S11 S12 S13 S15 S16 S17 S18 S5 S6 S7 S8 S9', 'a': 'S10 S12 S13 S14 S15 S17 S18', 'isTerminatingState': False}, 'S11 S12 S13 S15 S16 S17 S18 S5 S6 S7 S8 S9': {'b': 'S11 S12 S13 S15 S16 S17 S18 S5 S6 S7 S8 S9', 'a': 'S10 S12 S13 S14 S15 S17 S18', 'isTerminatingState': True}, 'S10 S12 S13 S14 S15 S17 S18': {'b': 'S16 S18', 'a': 'S14 S18', 'isTerminatingState': True}, 'S16 S18': {'isTerminatingState': True}, 'S14 S18': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mMin-DFA: {'startingState': 1, '2': {'a': '6', 'isTerminatingState': False}, '3': {'b': '4', 'a': '5', 'isTerminatingState': False}, '4': {'b': '4', 'a': '5', 'isTerminatingState': True}, '5': {'b': '1', 'a': '1', 'isTerminatingState': True}, '6': {'b': '7', 'isTerminatingState': False}, '7': {'b': '3', 'isTerminatingState': False}, '1': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "Processing successful!\n",
      "\u001b[1;33m##############################\n",
      "#     TEST CASE 6     #\n",
      "##############################\u001b[0m\n",
      "\n",
      "Regex: aab+a*ba?(a|b)\n",
      "regex after replacing character classes:  aab+a*ba?(a|b)\n",
      "regex after replacing hyphens with alternation:  aab+a*ba?(a|b)\n",
      "regex after inserting . operator:  a.a.b+.a*.b.a?.(a|b)\n",
      "\u001b[1;32mPostfix notation: aa.b+.a*.b.a?.ab|.\n",
      "\u001b[0m\n",
      "\u001b[1;36mNFA: {'startingState': 'S1', 'S1': {'isTerminatingState': False, 'a': 'S2'}, 'S10': {'isTerminatingState': False, 'ε': 'S11,S12'}, 'S11': {'isTerminatingState': False, 'ε': 'S9,S12'}, 'S12': {'isTerminatingState': False, 'ε': 'S13'}, 'S13': {'isTerminatingState': False, 'b': 'S14'}, 'S14': {'isTerminatingState': False, 'ε': 'S17'}, 'S15': {'isTerminatingState': False, 'a': 'S16'}, 'S16': {'isTerminatingState': False, 'ε': 'S18'}, 'S17': {'isTerminatingState': False, 'ε': 'S15,S18'}, 'S18': {'isTerminatingState': False, 'ε': 'S23'}, 'S19': {'isTerminatingState': False, 'a': 'S20'}, 'S2': {'isTerminatingState': False, 'ε': 'S3'}, 'S20': {'isTerminatingState': False, 'ε': 'S24'}, 'S21': {'isTerminatingState': False, 'b': 'S22'}, 'S22': {'isTerminatingState': False, 'ε': 'S24'}, 'S23': {'isTerminatingState': False, 'ε': 'S19,S21'}, 'S24': {'isTerminatingState': True}, 'S3': {'isTerminatingState': False, 'a': 'S4'}, 'S4': {'isTerminatingState': False, 'ε': 'S7'}, 'S5': {'isTerminatingState': False, 'b': 'S6'}, 'S6': {'isTerminatingState': False, 'ε': 'S7,S8'}, 'S7': {'isTerminatingState': False, 'ε': 'S5'}, 'S8': {'isTerminatingState': False, 'ε': 'S11'}, 'S9': {'isTerminatingState': False, 'a': 'S10'}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mDFA: {'startingState': 'S1', 'S1': {'a': 'S2 S3', 'isTerminatingState': False}, 'S2 S3': {'a': 'S4 S5 S7', 'isTerminatingState': False}, 'S4 S5 S7': {'b': 'S11 S12 S13 S5 S6 S7 S8 S9', 'isTerminatingState': False}, 'S11 S12 S13 S5 S6 S7 S8 S9': {'b': 'S11 S12 S13 S14 S15 S17 S18 S19 S21 S23 S5 S6 S7 S8 S9', 'a': 'S10 S11 S12 S13 S9', 'isTerminatingState': False}, 'S11 S12 S13 S14 S15 S17 S18 S19 S21 S23 S5 S6 S7 S8 S9': {'b': 'S11 S12 S13 S14 S15 S17 S18 S19 S21 S22 S23 S24 S5 S6 S7 S8 S9', 'a': 'S10 S11 S12 S13 S16 S18 S19 S20 S21 S23 S24 S9', 'isTerminatingState': False}, 'S10 S11 S12 S13 S9': {'b': 'S14 S15 S17 S18 S19 S21 S23', 'a': 'S10 S11 S12 S13 S9', 'isTerminatingState': False}, 'S11 S12 S13 S14 S15 S17 S18 S19 S21 S22 S23 S24 S5 S6 S7 S8 S9': {'b': 'S11 S12 S13 S14 S15 S17 S18 S19 S21 S22 S23 S24 S5 S6 S7 S8 S9', 'a': 'S10 S11 S12 S13 S16 S18 S19 S20 S21 S23 S24 S9', 'isTerminatingState': True}, 'S10 S11 S12 S13 S16 S18 S19 S20 S21 S23 S24 S9': {'b': 'S14 S15 S17 S18 S19 S21 S22 S23 S24', 'a': 'S10 S11 S12 S13 S20 S24 S9', 'isTerminatingState': True}, 'S14 S15 S17 S18 S19 S21 S23': {'b': 'S22 S24', 'a': 'S16 S18 S19 S20 S21 S23 S24', 'isTerminatingState': False}, 'S14 S15 S17 S18 S19 S21 S22 S23 S24': {'b': 'S22 S24', 'a': 'S16 S18 S19 S20 S21 S23 S24', 'isTerminatingState': True}, 'S10 S11 S12 S13 S20 S24 S9': {'b': 'S14 S15 S17 S18 S19 S21 S23', 'a': 'S10 S11 S12 S13 S9', 'isTerminatingState': True}, 'S22 S24': {'isTerminatingState': True}, 'S16 S18 S19 S20 S21 S23 S24': {'b': 'S22 S24', 'a': 'S20 S24', 'isTerminatingState': True}, 'S20 S24': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "\u001b[1;36mMin-DFA: {'startingState': 1, '1': {'b': '4', 'a': '9', 'isTerminatingState': True}, '3': {'b': '10', 'a': '11', 'isTerminatingState': False}, '4': {'b': '2', 'a': '13', 'isTerminatingState': False}, '5': {'a': '6', 'isTerminatingState': False}, '6': {'a': '7', 'isTerminatingState': False}, '7': {'b': '8', 'isTerminatingState': False}, '8': {'b': '3', 'a': '9', 'isTerminatingState': False}, '9': {'b': '4', 'a': '9', 'isTerminatingState': False}, '10': {'b': '10', 'a': '11', 'isTerminatingState': True}, '11': {'b': '12', 'a': '1', 'isTerminatingState': True}, '12': {'b': '2', 'a': '13', 'isTerminatingState': True}, '13': {'b': '2', 'a': '2', 'isTerminatingState': True}, '2': {'isTerminatingState': True}}\n",
      "\u001b[0m\n",
      "Processing successful!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_cases = [\n",
    "        r\"ab[ce-df]\",\n",
    "        r\"ab[ce-df\",\n",
    "        r\"ab?ab\",\n",
    "        r\"a[a-z0-1]\",\n",
    "        r\"abb+a?(a|b)\",\n",
    "        r\"aab+a*ba?(a|b)\",\n",
    "    ]\n",
    "\n",
    "    for idx, test_case in enumerate(test_cases, start=1):\n",
    "        print(f\"\\033[1;33m{'#' * 30}\\n#     TEST CASE {idx}     #\\n{'#' * 30}\\033[0m\\n\")\n",
    "\n",
    "        print(\"Regex:\", test_case)\n",
    "\n",
    "        processor = RegexProcessor(test_case)\n",
    "        status, nfa, minimized_dfa = processor.process(idx)\n",
    "\n",
    "        if status == \"Success\":\n",
    "            print(\"Processing successful!\")\n",
    "        else:\n",
    "            print(\"Invalid regex\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
